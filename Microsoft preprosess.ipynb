{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c322b3a6-a05d-42a4-b6dc-017b96e7b9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(r\"C:\\Users\\ASUS\\OneDrive\\Desktop\\MD112\\Capstone\\Microsoft\\GUIDE_Train.csv\")\n",
    "\n",
    "columns_to_keep = [\n",
    "    'IncidentId', 'AlertId', 'Timestamp', 'DetectorId', 'AlertTitle', 'Category', 'IncidentGrade', 'EntityType', 'EvidenceRole', \n",
    "    'DeviceId', 'IpAddress', 'Url', 'AccountSid', 'AccountUpn', 'AccountObjectId', 'AccountName', 'DeviceName', \n",
    "    'NetworkMessageId', 'RegistryKey', 'RegistryValueName', 'RegistryValueData', 'ApplicationId', 'ApplicationName', \n",
    "    'OAuthApplicationId', 'FileName', 'FolderPath', 'ResourceIdName', 'OSFamily', 'OSVersion', 'CountryCode', \n",
    "    'State', 'City'\n",
    "]\n",
    "\n",
    "df=df.loc[:, columns_to_keep]\n",
    "\n",
    "df['Timestamp'] = pd.to_datetime(df['Timestamp'], format = '%Y-%m-%dT%H:%M:%S.%fZ')\n",
    "df['IncidentGrade'] = df['IncidentGrade'].replace({'BenignPositive': 1, 'FalsePositive': 2, 'TruePositive': 3})\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('Processed_GUIDE_Train.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3dd5d14e-00c8-432d-8731-f9e4c4cd4587",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_10472\\1466830545.py:3: DtypeWarning: Columns (10,11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(r\"C:\\Users\\ASUS\\OneDrive\\Desktop\\MD112\\Capstone\\Microsoft\\GUIDE_Test.csv\")\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_10472\\1466830545.py:16: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df['IncidentGrade'] = df['IncidentGrade'].replace({'BenignPositive': 1, 'FalsePositive': 2, 'TruePositive': 3})\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(r\"C:\\Users\\ASUS\\OneDrive\\Desktop\\MD112\\Capstone\\Microsoft\\GUIDE_Test.csv\")\n",
    "\n",
    "columns_to_keep = [\n",
    "    'IncidentId', 'AlertId', 'Timestamp', 'DetectorId', 'AlertTitle', 'Category', 'IncidentGrade', 'EntityType', 'EvidenceRole', \n",
    "    'DeviceId', 'IpAddress', 'Url', 'AccountSid', 'AccountUpn', 'AccountObjectId', 'AccountName', 'DeviceName', \n",
    "    'NetworkMessageId', 'RegistryKey', 'RegistryValueName', 'RegistryValueData', 'ApplicationId', 'ApplicationName', \n",
    "    'OAuthApplicationId', 'FileName', 'FolderPath', 'ResourceIdName', 'OSFamily', 'OSVersion', 'CountryCode', \n",
    "    'State', 'City'\n",
    "]\n",
    "\n",
    "df=df.loc[:, columns_to_keep]\n",
    "\n",
    "df['Timestamp'] = pd.to_datetime(df['Timestamp'], format = '%Y-%m-%dT%H:%M:%S.%fZ')\n",
    "df['IncidentGrade'] = df['IncidentGrade'].replace({'BenignPositive': 1, 'FalsePositive': 2, 'TruePositive': 3})\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('Processed_GUIDE_Test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00a5222-846e-4b35-b7e8-78143c91e593",
   "metadata": {},
   "source": [
    "<!-- *Model* -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "21b0a00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('Processed_GUIDE_Test.xls')\n",
    "\n",
    "def remove_duplicates(df):\n",
    "    df = df.drop_duplicates()\n",
    "    return df\n",
    "\n",
    "def remove_outliers_iqr(df,column):\n",
    "    q1 = df[column].quantile(0.25)\n",
    "    q3 = df[column].quantile(0.75)\n",
    "    IQR = q3 - q1\n",
    "    lower_bound  = q1 - 1.5 * IQR\n",
    "    upper_bound = q3 + 1.5 * IQR\n",
    "    return df.loc[(df[column] > lower_bound) & (df[column] < upper_bound)]\n",
    "\n",
    "df = remove_duplicates(df)\n",
    "\n",
    "# columns_to_check = ['IncidentId', 'AlertId', 'DetectorId', 'DeviceId',\n",
    "#                      'ApplicationName', 'OAuthApplicationId', 'FileName', 'FolderPath', 'ResourceIdName']\n",
    "# for column in columns_to_check:\n",
    "#     df = remove_outliers_iqr(df, column)\n",
    "\n",
    "# print(\"Data after removing duplicates and outliers:\")\n",
    "df.to_csv('Processed_GUIDE_Test.csv', index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f17fcd38",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Processed_GUIDE_Train.xls')\n",
    "df = remove_duplicates(df)\n",
    "df.to_csv('Processed_GUIDE_Train.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b451327b-5c3d-4822-ad8d-2e0082004a68",
   "metadata": {},
   "source": [
    "**RandomForestClassifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e552ea3b-4456-4edb-bb3f-1088578bed31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.86\n",
      "Recall: 0.84\n",
      "F1 Score: 0.85\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# Load DataFrames\n",
    "train_df = pd.read_csv('Processed_GUIDE_Train.csv')\n",
    "test_df = pd.read_csv('Processed_GUIDE_Test.csv')\n",
    "\n",
    "# Drop rows with NaNs in IncidentGrade\n",
    "train_df = train_df.dropna(subset=['IncidentGrade'])\n",
    "\n",
    "# Process categorical columns in training DataFrame\n",
    "categorical_cols_train = train_df.select_dtypes(include=['object']).columns\n",
    "le = LabelEncoder()\n",
    "for col in categorical_cols_train:\n",
    "    train_df[col] = train_df[col].astype(str)\n",
    "    train_df[col] = le.fit_transform(train_df[col])\n",
    "\n",
    "# Process categorical columns in test DataFrame\n",
    "categorical_cols_test = test_df.select_dtypes(include=['object']).columns\n",
    "for col in categorical_cols_test:\n",
    "    test_df[col] = test_df[col].astype(str)\n",
    "    test_df[col] = le.fit_transform(test_df[col])\n",
    "\n",
    "# Split train data into feature and target\n",
    "X_train = train_df.drop('IncidentGrade', axis=1)\n",
    "y_train = train_df['IncidentGrade']\n",
    "\n",
    "X_test = test_df.drop('IncidentGrade', axis=1)\n",
    "y_test = test_df['IncidentGrade']\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Train a Random Forest Classifier\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "precision = precision_score(y_test, y_pred, average='macro')\n",
    "recall = recall_score(y_test, y_pred, average='macro')\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "print(f'Precision: {precision:.2f}')\n",
    "print(f'Recall: {recall:.2f}')\n",
    "print(f'F1 Score: {f1:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd34ce1-7717-42ea-a882-da92306f7c0b",
   "metadata": {},
   "source": [
    "**Decision Tree Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c61193e3-f898-4814-9392-0ec46e4e4e7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.78\n",
      "Recall: 0.78\n",
      "F1 Score: 0.78\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# Load DataFrames\n",
    "train_df = pd.read_csv('Processed_GUIDE_Train.csv')\n",
    "test_df = pd.read_csv('Processed_GUIDE_Test.csv')\n",
    "\n",
    "# Drop rows with NaNs in IncidentGrade\n",
    "train_df = train_df.dropna(subset=['IncidentGrade'])\n",
    "\n",
    "# Process categorical columns in training DataFrame\n",
    "categorical_cols_train = train_df.select_dtypes(include=['object']).columns\n",
    "le = LabelEncoder()\n",
    "for col in categorical_cols_train:\n",
    "    train_df[col] = train_df[col].astype(str)\n",
    "    train_df[col] = le.fit_transform(train_df[col])\n",
    "\n",
    "# Process categorical columns in test DataFrame\n",
    "categorical_cols_test = test_df.select_dtypes(include=['object']).columns\n",
    "for col in categorical_cols_test:\n",
    "    test_df[col] = test_df[col].astype(str)\n",
    "    test_df[col] = le.fit_transform(test_df[col])\n",
    "\n",
    "# Split train data into feature and target\n",
    "X_train = train_df.drop('IncidentGrade', axis=1)\n",
    "y_train = train_df['IncidentGrade']\n",
    "\n",
    "X_test = test_df.drop('IncidentGrade', axis=1)\n",
    "y_test = test_df['IncidentGrade']\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Train a Decision Tree Classifier\n",
    "model = DecisionTreeClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "precision = precision_score(y_test, y_pred, average='macro')\n",
    "recall = recall_score(y_test, y_pred, average='macro')\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "print(f'Precision: {precision:.2f}')\n",
    "print(f'Recall: {recall:.2f}')\n",
    "print(f'F1 Score: {f1:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baed3f8b-ca24-4398-aa29-9c1922bd6e4e",
   "metadata": {},
   "source": [
    "**Neural Network Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6df8d165-13fb-4a54-bcb2-c17fa7d97e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cbfd3adb-0ff0-477a-b846-d2cb3200b39a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m236638/236638\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m411s\u001b[0m 2ms/step - accuracy: 0.7102 - loss: 0.6561 - val_accuracy: 0.7691 - val_loss: 0.5391\n",
      "Epoch 2/10\n",
      "\u001b[1m236638/236638\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m457s\u001b[0m 2ms/step - accuracy: 0.7704 - loss: 0.5356 - val_accuracy: 0.7793 - val_loss: 0.5175\n",
      "Epoch 3/10\n",
      "\u001b[1m236638/236638\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m645s\u001b[0m 3ms/step - accuracy: 0.7799 - loss: 0.5137 - val_accuracy: 0.7832 - val_loss: 0.5064\n",
      "Epoch 4/10\n",
      "\u001b[1m236638/236638\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m478s\u001b[0m 2ms/step - accuracy: 0.7844 - loss: 0.5037 - val_accuracy: 0.7874 - val_loss: 0.4953\n",
      "Epoch 5/10\n",
      "\u001b[1m236638/236638\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m467s\u001b[0m 2ms/step - accuracy: 0.7876 - loss: 0.4978 - val_accuracy: 0.7897 - val_loss: 0.4908\n",
      "Epoch 6/10\n",
      "\u001b[1m236638/236638\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m585s\u001b[0m 2ms/step - accuracy: 0.7900 - loss: 0.4925 - val_accuracy: 0.7939 - val_loss: 0.4870\n",
      "Epoch 7/10\n",
      "\u001b[1m236638/236638\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m699s\u001b[0m 3ms/step - accuracy: 0.7920 - loss: 0.4891 - val_accuracy: 0.7939 - val_loss: 0.4853\n",
      "Epoch 8/10\n",
      "\u001b[1m236638/236638\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m687s\u001b[0m 3ms/step - accuracy: 0.7927 - loss: 0.4870 - val_accuracy: 0.7942 - val_loss: 0.4834\n",
      "Epoch 9/10\n",
      "\u001b[1m 39608/236638\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:08\u001b[0m 2ms/step - accuracy: 0.7940 - loss: 0.4851"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m236638/236638\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m474s\u001b[0m 2ms/step - accuracy: 0.7940 - loss: 0.4846 - val_accuracy: 0.7962 - val_loss: 0.4808\n",
      "Epoch 10/10\n",
      "\u001b[1m236638/236638\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m495s\u001b[0m 2ms/step - accuracy: 0.7945 - loss: 0.4832 - val_accuracy: 0.7959 - val_loss: 0.4830\n",
      "\u001b[1m129625/129625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 1ms/step\n",
      "Precision: 0.74\n",
      "Recall: 0.69\n",
      "F1 Score: 0.71\n"
     ]
    }
   ],
   "source": [
    "# Load DataFrames\n",
    "train_df = pd.read_csv('Processed_GUIDE_Train.csv')\n",
    "test_df = pd.read_csv('Processed_GUIDE_Test.csv')\n",
    "\n",
    "# Drop rows with NaNs in IncidentGrade\n",
    "train_df = train_df.dropna(subset=['IncidentGrade'])\n",
    "\n",
    "# Process categorical columns in training DataFrame\n",
    "categorical_cols_train = train_df.select_dtypes(include=['object']).columns\n",
    "le = LabelEncoder()\n",
    "for col in categorical_cols_train:\n",
    "    train_df[col] = train_df[col].astype(str)\n",
    "    train_df[col] = le.fit_transform(train_df[col])\n",
    "\n",
    "# Process categorical columns in test DataFrame\n",
    "categorical_cols_test = test_df.select_dtypes(include=['object']).columns\n",
    "for col in categorical_cols_test:\n",
    "    test_df[col] = test_df[col].astype(str)\n",
    "    test_df[col] = le.fit_transform(test_df[col])\n",
    "\n",
    "# Split train data into feature and target\n",
    "X_train = train_df.drop('IncidentGrade', axis=1)\n",
    "y_train = train_df['IncidentGrade']\n",
    "\n",
    "X_test = test_df.drop('IncidentGrade', axis=1)\n",
    "y_test = test_df['IncidentGrade']\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Convert target to categorical\n",
    "y_train = tf.keras.utils.to_categorical(y_train)\n",
    "y_test = tf.keras.utils.to_categorical(y_test)\n",
    "\n",
    "\n",
    "# Build the neural network model\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=X_train.shape[1], activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(y_train.shape[1], activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
    "\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_test_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Evaluate\n",
    "precision = precision_score(y_test_classes, y_pred_classes, average='macro')\n",
    "recall = recall_score(y_test_classes, y_pred_classes, average='macro')\n",
    "f1 = f1_score(y_test_classes, y_pred_classes, average='macro')\n",
    "\n",
    "print(f'Precision: {precision:.2f}')\n",
    "print(f'Recall: {recall:.2f}')\n",
    "print(f'F1 Score: {f1:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b13610-5e01-4dfc-b171-941744188e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# Initialize model and scaler\n",
    "model = RandomForestClassifier()\n",
    "scaler = StandardScaler()\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Process chunks\n",
    "chunk_size = 10000\n",
    "for chunk in pd.read_csv('Processed_GUIDE_Train.csv', chunksize=chunk_size):\n",
    "    chunk = chunk.dropna(subset=['IncidentGrade'])\n",
    "    for col in chunk.select_dtypes(include=['object']).columns:\n",
    "        chunk[col] = le.fit_transform(chunk[col].astype(str))\n",
    "    \n",
    "    X_train = chunk.drop('IncidentGrade', axis=1)\n",
    "    y_train = chunk['IncidentGrade']\n",
    "    \n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate on test data\n",
    "test_df = pd.read_csv('Processed_GUIDE_Test.csv')\n",
    "test_df = test_df.dropna(subset=['IncidentGrade'])\n",
    "for col in test_df.select_dtypes(include=['object']).columns:\n",
    "    test_df[col] = le.fit_transform(test_df[col].astype(str))\n",
    "\n",
    "X_test = test_df.drop('IncidentGrade', axis=1)\n",
    "y_test = test_df['IncidentGrade']\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "precision = precision_score(y_test, y_pred, average='macro')\n",
    "recall = recall_score(y_test, y_pred, average='macro')\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "print(f'Precision: {precision:.2f}')\n",
    "print(f'Recall: {recall:.2f}')\n",
    "print(f'F1 Score: {f1:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c6a604c-efda-48fd-87f5-f7db5ba67345",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# Load DataFrames\n",
    "train_df = pd.read_csv('Processed_GUIDE_Train.csv')\n",
    "test_df = pd.read_csv('Processed_GUIDE_Test.csv')\n",
    "\n",
    "# Drop rows with NaNs in IncidentGrade\n",
    "train_df = train_df.dropna(subset=['IncidentGrade'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "516d5f4e-b5c0-4849-82bd-a909d826bce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process categorical columns in training DataFrame\n",
    "categorical_cols_train = train_df.select_dtypes(include=['object']).columns\n",
    "le = LabelEncoder()\n",
    "for col in categorical_cols_train:\n",
    "    train_df[col] = train_df[col].astype(str)\n",
    "    train_df[col] = le.fit_transform(train_df[col])\n",
    "\n",
    "# Process categorical columns in test DataFrame\n",
    "categorical_cols_test = test_df.select_dtypes(include=['object']).columns\n",
    "for col in categorical_cols_test:\n",
    "    test_df[col] = test_df[col].astype(str)\n",
    "    test_df[col] = le.fit_transform(test_df[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8681c38-4970-4d46-b3e3-835221b20412",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df.drop('IncidentGrade', axis=1)\n",
    "y_train = train_df['IncidentGrade']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "527d494c-0f22-49bf-80d5-461477e74a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_df.drop('IncidentGrade', axis=1)\n",
    "y_test = test_df['IncidentGrade']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "17c31bfd-5213-4526-bf7f-6cd56791d48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b5d03e-df98-428d-9e50-aa8f35cb3443",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8bd56eda-5df5-4d6e-bd32-027ebdfdb6ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_14832\\2651829891.py:15: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df['IncidentGrade'] = df['IncidentGrade'].replace({'BenignPositive': 1, 'FalsePositive': 2, 'TruePositive': 3})\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(r\"C:\\Users\\ASUS\\OneDrive\\Desktop\\MD112\\Capstone\\Microsoft\\GUIDE_Train.csv\")\n",
    "columns_to_keep = [\n",
    "    'IncidentId', 'AlertId', 'Timestamp', 'DetectorId', 'AlertTitle', 'Category', 'IncidentGrade', 'EntityType', 'EvidenceRole', \n",
    "    'DeviceId', 'IpAddress', 'Url', 'AccountSid', 'AccountUpn', 'AccountObjectId', 'AccountName', 'DeviceName', \n",
    "    'NetworkMessageId', 'RegistryKey', 'RegistryValueName', 'RegistryValueData', 'ApplicationId', 'ApplicationName', \n",
    "    'OAuthApplicationId', 'FileName', 'FolderPath', 'ResourceIdName', 'OSFamily', 'OSVersion', 'CountryCode', \n",
    "    'State', 'City'\n",
    "]\n",
    "\n",
    "df=df.loc[:, columns_to_keep]\n",
    "\n",
    "df['Timestamp'] = pd.to_datetime(df['Timestamp'], format = '%Y-%m-%dT%H:%M:%S.%fZ')\n",
    "df['IncidentGrade'] = df['IncidentGrade'].replace({'BenignPositive': 1, 'FalsePositive': 2, 'TruePositive': 3})\n",
    "\n",
    "sample_df = df.sample(n=100000, random_state=42)\n",
    "sample_df.to_csv('Sample_GUIDE_Train.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78ee5ee2-e45e-4a43-ba3a-c343f87e9634",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_14832\\248290320.py:3: DtypeWarning: Columns (10,11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(r\"C:\\Users\\ASUS\\OneDrive\\Desktop\\MD112\\Capstone\\Microsoft\\GUIDE_Test.csv\")\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_14832\\248290320.py:16: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df['IncidentGrade'] = df['IncidentGrade'].replace({'BenignPositive': 1, 'FalsePositive': 2, 'TruePositive': 3})\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(r\"C:\\Users\\ASUS\\OneDrive\\Desktop\\MD112\\Capstone\\Microsoft\\GUIDE_Test.csv\")\n",
    "\n",
    "columns_to_keep = [\n",
    "    'IncidentId', 'AlertId', 'Timestamp', 'DetectorId', 'AlertTitle', 'Category', 'IncidentGrade', 'EntityType', 'EvidenceRole', \n",
    "    'DeviceId', 'IpAddress', 'Url', 'AccountSid', 'AccountUpn', 'AccountObjectId', 'AccountName', 'DeviceName', \n",
    "    'NetworkMessageId', 'RegistryKey', 'RegistryValueName', 'RegistryValueData', 'ApplicationId', 'ApplicationName', \n",
    "    'OAuthApplicationId', 'FileName', 'FolderPath', 'ResourceIdName', 'OSFamily', 'OSVersion', 'CountryCode', \n",
    "    'State', 'City'\n",
    "]\n",
    "\n",
    "df=df.loc[:, columns_to_keep]\n",
    "\n",
    "df['Timestamp'] = pd.to_datetime(df['Timestamp'], format = '%Y-%m-%dT%H:%M:%S.%fZ')\n",
    "df['IncidentGrade'] = df['IncidentGrade'].replace({'BenignPositive': 1, 'FalsePositive': 2, 'TruePositive': 3})\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "sample_df = df.sample(n=100000, random_state=42)\n",
    "sample_df.to_csv('Sample_GUIDE_Test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c58edafd-7297-4307-95ab-b4a47289542f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.83\n",
      "Recall: 0.80\n",
      "F1 Score: 0.81\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# Load DataFrames\n",
    "train_df = pd.read_csv('Sample_GUIDE_Train.csv')\n",
    "test_df = pd.read_csv('Sample_GUIDE_Test.csv')\n",
    "\n",
    "# Drop rows with NaNs in IncidentGrade\n",
    "train_df = train_df.dropna(subset=['IncidentGrade'])\n",
    "\n",
    "# Process categorical columns in training DataFrame\n",
    "categorical_cols_train = train_df.select_dtypes(include=['object']).columns\n",
    "le = LabelEncoder()\n",
    "for col in categorical_cols_train:\n",
    "    train_df[col] = train_df[col].astype(str)\n",
    "    train_df[col] = le.fit_transform(train_df[col])\n",
    "\n",
    "# Process categorical columns in test DataFrame\n",
    "categorical_cols_test = test_df.select_dtypes(include=['object']).columns\n",
    "for col in categorical_cols_test:\n",
    "    test_df[col] = test_df[col].astype(str)\n",
    "    test_df[col] = le.fit_transform(test_df[col])\n",
    "\n",
    "# Split train data into feature and target\n",
    "X_train = train_df.drop('IncidentGrade', axis=1)\n",
    "y_train = train_df['IncidentGrade']\n",
    "\n",
    "X_test = test_df.drop('IncidentGrade', axis=1)\n",
    "y_test = test_df['IncidentGrade']\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Train a Random Forest Classifier\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "precision = precision_score(y_test, y_pred, average='macro')\n",
    "recall = recall_score(y_test, y_pred, average='macro')\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "print(f'Precision: {precision:.2f}')\n",
    "print(f'Recall: {recall:.2f}')\n",
    "print(f'F1 Score: {f1:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a41ff75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load DataFrames\n",
    "train_df = pd.read_csv('Processed_GUIDE_Train.xls')\n",
    "test_df = pd.read_csv('Processed_GUIDE_Test.xls')\n",
    "\n",
    "# Sample a subset of the data to avoid MemoryError\n",
    "train_df = train_df.sample(n=100000, random_state=42)\n",
    "test_df = test_df.sample(n=100000, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26b1bdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         IncidentId  AlertId            Timestamp  DetectorId  AlertTitle  \\\n",
      "8036545       49334   360163  2024-06-11 18:50:05          10           8   \n",
      "3828916       52272    14178  2024-06-09 08:02:17           1           1   \n",
      "4404679       21863    14266  2024-06-13 13:54:51          18          14   \n",
      "8854100        3044     2411  2024-06-06 07:11:21          70        1871   \n",
      "7977240         155   402605  2024-06-09 04:02:36           4           3   \n",
      "...             ...      ...                  ...         ...         ...   \n",
      "1259055      106728   444574  2024-06-03 12:33:55         867       53051   \n",
      "8211233        1245   547267  2024-06-02 01:10:23          14          12   \n",
      "6571643        1161   191438  2024-06-03 23:23:54           3           4   \n",
      "1356383      539055   549552  2024-06-03 05:38:33           5          34   \n",
      "3825628       72340    95117  2024-06-11 15:28:42          13          11   \n",
      "\n",
      "                   Category  IncidentGrade   EntityType EvidenceRole  \\\n",
      "8036545       InitialAccess            1.0  MailMessage      Related   \n",
      "3828916       InitialAccess            1.0  MailMessage      Related   \n",
      "4404679        Exfiltration            1.0  MailMessage     Impacted   \n",
      "8854100        Exfiltration            2.0  MailMessage     Impacted   \n",
      "7977240       InitialAccess            3.0         User     Impacted   \n",
      "...                     ...            ...          ...          ...   \n",
      "1259055        Exfiltration            NaN         User     Impacted   \n",
      "8211233    CredentialAccess            3.0         User     Impacted   \n",
      "6571643  SuspiciousActivity            1.0           Ip      Related   \n",
      "1356383  SuspiciousActivity            3.0         User     Impacted   \n",
      "3825628       InitialAccess            3.0  MailMessage      Related   \n",
      "\n",
      "         DeviceId  ...  ApplicationName  OAuthApplicationId  FileName  \\\n",
      "8036545     98799  ...             3421                 881    289573   \n",
      "3828916     98799  ...             3421                 881    289573   \n",
      "4404679     98799  ...             3421                 881    289573   \n",
      "8854100     98799  ...             3421                 881    289573   \n",
      "7977240     98799  ...             3421                 881    289573   \n",
      "...           ...  ...              ...                 ...       ...   \n",
      "1259055     98799  ...             3421                 881    289573   \n",
      "8211233     98799  ...             3421                 881    289573   \n",
      "6571643     98799  ...             3421                 881    289573   \n",
      "1356383     98799  ...             3421                 881    289573   \n",
      "3825628     98799  ...             3421                 881    289573   \n",
      "\n",
      "         FolderPath  ResourceIdName  OSFamily  OSVersion  CountryCode  State  \\\n",
      "8036545      117668            3586         5         66          242   1445   \n",
      "3828916      117668            3586         5         66          242   1445   \n",
      "4404679      117668            3586         5         66          242   1445   \n",
      "8854100      117668            3586         5         66          242   1445   \n",
      "7977240      117668            3586         5         66          242   1445   \n",
      "...             ...             ...       ...        ...          ...    ...   \n",
      "1259055      117668            3586         5         66          242   1445   \n",
      "8211233      117668            3586         5         66          242   1445   \n",
      "6571643      117668            3586         5         66          242   1445   \n",
      "1356383      117668            3586         5         66          242   1445   \n",
      "3825628      117668            3586         5         66          242   1445   \n",
      "\n",
      "          City  \n",
      "8036545  10630  \n",
      "3828916  10630  \n",
      "4404679  10630  \n",
      "8854100  10630  \n",
      "7977240  10630  \n",
      "...        ...  \n",
      "1259055  10630  \n",
      "8211233  10630  \n",
      "6571643  10630  \n",
      "1356383  10630  \n",
      "3825628  10630  \n",
      "\n",
      "[100000 rows x 32 columns]\n",
      "         IncidentId  AlertId            Timestamp  DetectorId  AlertTitle  \\\n",
      "2480092         783    39817  2024-06-08 22:30:10           1           1   \n",
      "437473         3036    17081  2024-06-15 21:14:41         838         465   \n",
      "3166255       24609    50121  2024-06-08 22:17:24           1           1   \n",
      "2264349         210   414177  2024-06-10 14:09:04           0           0   \n",
      "808028       210245   761114  2024-06-04 07:29:07           2           2   \n",
      "...             ...      ...                  ...         ...         ...   \n",
      "929003         8004     5716  2024-06-16 12:23:32          64          42   \n",
      "1612571       46642   335213  2024-06-09 18:44:56           0           0   \n",
      "3445815       54423   422119  2024-06-11 01:09:23          44         114   \n",
      "2121558       66286    53074  2024-06-12 18:24:25           1           1   \n",
      "3650197       90692  1644481  2024-06-15 16:05:40         318         111   \n",
      "\n",
      "                  Category  IncidentGrade EntityType EvidenceRole  DeviceId  \\\n",
      "2480092      InitialAccess              1    Mailbox     Impacted     98799   \n",
      "437473    CredentialAccess              3       User     Impacted     98799   \n",
      "3166255      InitialAccess              1        Url      Related     98799   \n",
      "2264349      InitialAccess              3         Ip      Related     98799   \n",
      "808028   CommandAndControl              1    Machine     Impacted      8369   \n",
      "...                    ...            ...        ...          ...       ...   \n",
      "929003   CommandAndControl              1         Ip      Related     98799   \n",
      "1612571      InitialAccess              3         Ip      Related     98799   \n",
      "3445815   UnwantedSoftware              1       File      Related     98799   \n",
      "2121558      InitialAccess              1        Url      Related     98799   \n",
      "3650197   CredentialAccess              1       User     Impacted     98799   \n",
      "\n",
      "         ...  ApplicationName  OAuthApplicationId  FileName  FolderPath  \\\n",
      "2480092  ...             3421                 881    289573      117668   \n",
      "437473   ...             3421                 881    289573      117668   \n",
      "3166255  ...             3421                 881    289573      117668   \n",
      "2264349  ...             3421                 881    289573      117668   \n",
      "808028   ...             3421                 881    289573      117668   \n",
      "...      ...              ...                 ...       ...         ...   \n",
      "929003   ...             3421                 881    289573      117668   \n",
      "1612571  ...             3421                 881    289573      117668   \n",
      "3445815  ...             3421                 881    225220         109   \n",
      "2121558  ...             3421                 881    289573      117668   \n",
      "3650197  ...             3421                 881    289573      117668   \n",
      "\n",
      "         ResourceIdName  OSFamily  OSVersion  CountryCode  State   City  \n",
      "2480092            3586         5         66          242   1445  10630  \n",
      "437473             3586         5         66          242   1445  10630  \n",
      "3166255            3586         5         66          242   1445  10630  \n",
      "2264349            3586         5         66            1      0      0  \n",
      "808028             3586         0          0          242   1445  10630  \n",
      "...                 ...       ...        ...          ...    ...    ...  \n",
      "929003             3586         5         66          242   1445  10630  \n",
      "1612571            3586         5         66            0      1      1  \n",
      "3445815            3586         5         66          242   1445  10630  \n",
      "2121558            3586         5         66          242   1445  10630  \n",
      "3650197            3586         5         66          242   1445  10630  \n",
      "\n",
      "[100000 rows x 32 columns]\n"
     ]
    }
   ],
   "source": [
    "print(train_df)\n",
    "print(test_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "448773a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in train_df['IncidentGrade']:\n",
      "[ 1.  2.  3. nan]\n",
      "\n",
      "Counts of unique values in train_df['IncidentGrade']:\n",
      "IncidentGrade\n",
      "1.0    42822\n",
      "3.0    35105\n",
      "2.0    21505\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Unique values in test_df['IncidentGrade']:\n",
      "[1 3 2]\n",
      "\n",
      "Counts of unique values in test_df['IncidentGrade']:\n",
      "IncidentGrade\n",
      "1    42297\n",
      "3    36049\n",
      "2    21654\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# For train_df\n",
    "unique_train = train_df['IncidentGrade'].unique()\n",
    "count_train = train_df['IncidentGrade'].value_counts()\n",
    "\n",
    "print(\"Unique values in train_df['IncidentGrade']:\")\n",
    "print(unique_train)\n",
    "print(\"\\nCounts of unique values in train_df['IncidentGrade']:\")\n",
    "print(count_train)\n",
    "\n",
    "# For test_df\n",
    "unique_test = test_df['IncidentGrade'].unique()\n",
    "count_test = test_df['IncidentGrade'].value_counts()\n",
    "\n",
    "print(\"\\nUnique values in test_df['IncidentGrade']:\")\n",
    "print(unique_test)\n",
    "print(\"\\nCounts of unique values in test_df['IncidentGrade']:\")\n",
    "print(count_test)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
